{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Irenekayla/ML_Notebooks/blob/main/super_resolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bHcckOsR20dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do set your runtime to GPU. You will need it\n",
        "import torch\n",
        "import math\n",
        "from os import listdir\n",
        "import numpy as np\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "oCJeq-yrz_Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# super resolution using ESRCNN"
      ],
      "metadata": {
        "id": "H7Cu5NqI0AD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import Compose, RandomCrop, ToTensor, ToPILImage, CenterCrop, Resize"
      ],
      "metadata": {
        "id": "jIHUiuIR0zm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "from os.path import join\n",
        "torch.autograd.set_detect_anomaly(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4dFZgOK04mr",
        "outputId": "5cab01ab-1374-4c66-9f11-c29b4a360719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f202b8dfbe0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UPSCALE_FACTOR = 4\n",
        "CROP_SIZE = 300"
      ],
      "metadata": {
        "id": "Lgc3Pohi6Gu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, I will load in some code for the dataset and dataloaders.\n",
        "# Link to this notebook will be in the description, so you can get it from there\n",
        "def is_image_file(filename):\n",
        "    return any(filename.endswith(extension) for extension in ['.tiff'])\n",
        "\n",
        "\n",
        "def calculate_valid_crop_size(crop_size, upscale_factor):\n",
        "    return crop_size - (crop_size % upscale_factor)\n",
        "\n",
        "\n",
        "def input_transform(crop_size):\n",
        "    return Compose([\n",
        "        RandomCrop(crop_size),\n",
        "        ToTensor(),\n",
        "    ])\n",
        "def get_training_set(upscale_factor):\n",
        "    root_dir = ''\n",
        "    train_dir = join(root_dir, \"train\")\n",
        "    crop_size = calculate_valid_crop_size(256, upscale_factor)\n",
        "\n",
        "    return TrainDatasetFromFolder(train_dir,\n",
        "                             input_transform=input_transform(crop_size, upscale_factor),\n",
        "                             target_transform=target_transform(crop_size))\n",
        "\n",
        "\n",
        "def get_test_set(upscale_factor):\n",
        "    root_dir = ''\n",
        "    test_dir = join(root_dir, \"test\")\n",
        "    crop_size = calculate_valid_crop_size(256, upscale_factor)\n",
        "\n",
        "    return TrainDatasetFromFolder(test_dir,\n",
        "                             input_transform=input_transform(crop_size, upscale_factor),\n",
        "                             target_transform=target_transform(crop_size))\n",
        "\n",
        "def target_transform(crop_size, upscale_factor):\n",
        "    return Compose([\n",
        "        ToPILImage(),\n",
        "        Resize(crop_size // upscale_factor, interpolation=Image.BICUBIC),\n",
        "        ToTensor()\n",
        "    ])\n",
        "\n",
        "\n",
        "def display_transform():\n",
        "    return Compose([\n",
        "        ToPILImage(),\n",
        "        Resize(400),\n",
        "        CenterCrop(400),\n",
        "        ToTensor()\n",
        "    ])\n",
        "\n",
        "\n",
        "class TrainDatasetFromFolder(Dataset):\n",
        "    def __init__(self, dataset_dir, crop_size, upscale_factor):\n",
        "        super(TrainDatasetFromFolder, self).__init__()\n",
        "        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n",
        "        crop_size = calculate_valid_crop_size(crop_size, upscale_factor)\n",
        "        self.hr_transform = target_transform(crop_size)\n",
        "        self.lr_transform = input_transform(crop_size, upscale_factor)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        hr_image = self.hr_transform(Image.open(self.image_filenames[index]))\n",
        "        lr_image = self.lr_transform(hr_image)\n",
        "        return lr_image, hr_image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)"
      ],
      "metadata": {
        "id": "Ha8ILRKT1M53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "train_set = TrainDatasetFromFolder(\"/kaggle/input/denoised\", crop_size=CROP_SIZE,\n",
        "                                   upscale_factor=UPSCALE_FACTOR)\n",
        "trainloader = DataLoader(train_set, batch_size=64, num_workers=4, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "MSKKHJvn1aMP",
        "outputId": "59cf6787-6038-49cb-98e6-16f2a47dac25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/kaggle/input/denoised'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e96f2b6ba790>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_set = TrainDatasetFromFolder(\"/kaggle/input/denoised\", crop_size=CROP_SIZE,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                    upscale_factor=UPSCALE_FACTOR)\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-9189f1b97aa4>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset_dir, crop_size, upscale_factor)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupscale_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainDatasetFromFolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_image_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mcrop_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_valid_crop_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupscale_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhr_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/denoised'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, upscale_factor):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
        "        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
        "        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
        "        self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
        "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.pixel_shuffle(self.conv4(x))\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv4.weight)"
      ],
      "metadata": {
        "id": "CXChdrZg4bFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "from math import log10\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "print('===> Loading datasets')\n",
        "train_set = get_training_set(UPSCALE_FACTOR)\n",
        "test_set = get_test_set(UPSCALE_FACTOR)\n",
        "training_data_loader = DataLoader(dataset=train_set, num_workers=2, batch_size=32, shuffle=True)\n",
        "testing_data_loader = DataLoader(dataset=test_set, num_workers=2, batch_size=32, shuffle=False)\n",
        "\n",
        "print('===> Building model')\n",
        "model = Net(upscale_factor=UPSCALE_FACTOR).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    epoch_loss = 0\n",
        "    for iteration, batch in enumerate(training_data_loader, 1):\n",
        "        input, target = batch[0].to(device), batch[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(input), target)\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(\"===> Epoch[{}]({}/{}): Loss: {:.4f}\".format(epoch, iteration, len(training_data_loader), loss.item()))\n",
        "\n",
        "    print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(training_data_loader)))\n",
        "\n",
        "\n",
        "def test():\n",
        "    avg_psnr = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in testing_data_loader:\n",
        "            input, target = batch[0].to(device), batch[1].to(device)\n",
        "\n",
        "            prediction = model(input)\n",
        "            mse = criterion(prediction, target)\n",
        "            psnr = 10 * log10(1 / mse.item())\n",
        "            avg_psnr += psnr\n",
        "    print(\"===> Avg. PSNR: {:.4f} dB\".format(avg_psnr / len(testing_data_loader)))\n",
        "\n",
        "\n",
        "def checkpoint(epoch):\n",
        "    model_out_path = \"model_epoch_{}.pth\".format(epoch)\n",
        "    torch.save(model, model_out_path)\n",
        "    print(\"Checkpoint saved to {}\".format(model_out_path))\n",
        "\n",
        "for epoch in range(1, 100 + 1):\n",
        "    train(epoch)\n",
        "    test()\n",
        "    checkpoint(epoch)"
      ],
      "metadata": {
        "id": "G5ggVNR74eQD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}